#cloud-config
package_update: true
package_upgrade: true

packages:
  - curl
  - wget
  - unzip
  - htop
  - build-essential
  - gcc-12
  - g++-12
  - ubuntu-drivers-common

# Mount the data disk for Ollama models
disk_setup:
  /dev/sdc:
    table_type: gpt
    layout: true

fs_setup:
  - label: ollama-models
    filesystem: ext4
    device: /dev/sdc1

mounts:
  - ["/dev/disk/by-label/ollama-models", "/opt/ollama-models", "ext4", "defaults", "0", "2"]

runcmd:
  # Install NVIDIA drivers using ubuntu-drivers
  - ubuntu-drivers autoinstall
  
  # Create ollama user and group
  - useradd -r -s /bin/false -d /opt/ollama ollama
  
  # Create directories and set permissions
  - mkdir -p /opt/ollama /opt/ollama-models
  - chown ollama:ollama /opt/ollama /opt/ollama-models
  
  # Install Ollama
  - curl -fsSL https://ollama.com/install.sh | sh
  
  # Create systemd service override to use data disk and all A100 GPUs
  - mkdir -p /etc/systemd/system/ollama.service.d
  - |
    cat > /etc/systemd/system/ollama.service.d/override.conf << 'EOF'
    [Service]
    Environment="OLLAMA_MODELS=/opt/ollama-models"
    Environment="OLLAMA_HOST=0.0.0.0:11434"
    Environment="CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7"
    Environment="OLLAMA_NUM_GPU=8"
    EOF
  
  # Enable and start Ollama service
  - systemctl daemon-reload
  - systemctl enable --now ollama
  
  # Wait for service to be ready
  - sleep 10
  
  # Start Ollama serve in background and download a lightweight model for testing
  - sudo -u ollama OLLAMA_MODELS=/opt/ollama-models nohup /usr/local/bin/ollama serve &
  - sleep 5
  - sudo -u ollama OLLAMA_MODELS=/opt/ollama-models /usr/local/bin/ollama pull gpt-oss

write_files:
  - path: /etc/logrotate.d/ollama
    content: |
      /var/log/ollama/*.log {
          daily
          rotate 7
          compress
          delaycompress
          missingok
          notifempty
          create 644 ollama ollama
      }